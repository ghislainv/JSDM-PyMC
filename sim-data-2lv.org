# -*- mode: org -*-
# -*- coding: utf-8 -*-
# -*- org-src-preserve-indentation: t; org-edit-src-content: 0; -*-

# ==============================================================================
# author          :Ghislain Vieilledent
# email           :ghislain.vieilledent@cirad.fr, ghislainv@gmail.com
# web             :https://ecology.ghislainv.fr
# license         :GPLv3
# ==============================================================================

#+title: Ordering species to correct for ineffective constraints in joint species distribution models with latent variables
#+author: Ghislain Vieilledent
#+email: ghislain.vieilledent@cirad.fr

#+LANGUAGE: en
#+TAGS: Blog(B) noexport(n) Stats(S)
#+TAGS: Ecology(E) R(R) OrgMode(O) Python(P)
#+OPTIONS: H:3 num:t toc:t \n:nil @:t ::t |:t ^:{} -:t f:t *:t <:t tex:t
#+OPTIONS: author:t email:t
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

# HTML themes
#+HTML_DOCTYPE: html5
#+OPTIONS: html-style:nil html-scripts:nil html5-fancy:t
#+OPTIONS: html-postamble:nil html-preamble:nil
#+HTML_HEAD: <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@xz/fonts@1/serve/inter.css">
#+HTML_HEAD: <link rel="stylesheet" href="style/new.css">
#+HTML_HEAD: <link rel="stylesheet" href="style/mycss.css">
# #+HTML_HEAD: <link rel="stylesheet" type="text/css" href="style/worg.css"/>

#+PROPERTY: header-args :eval never-export

* Installing PyMC in a Python virtual environment

The best way to install the package is to create a Python virtual environment, for example using =conda=. You first need to have [[https://docs.conda.io/en/latest/miniconda.html][miniconda3]] installed. Then, create a [[https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html][conda environment]] and install the PyMC package with the following commands:

#+begin_src shell :eval no
conda create --name JSDM-PyMC -c conda-forge python=3.9
conda activate JSDM-PyMC
conda install -c conda-forge mamba
mamba install -c conda-forge "pymc>=4"
conda install -c conda-forge scikit-learn flake8 jedi tabular
#+end_src

To deactivate and delete the conda environment, use the following commands:

#+begin_src shell :eval no
conda deactivate
conda env remove --name JSDM-PyMC
#+end_src

#+RESULTS:

* Import libraries

#+begin_src python :tangle yes :comments both :results output :session :exports both
import os
import sys

import arviz as az
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import cloudpickle
import pymc as pm
import pytensor.tensor as pt
from tabulate import tabulate

print(f"Running on PyMC v{pm.__version__}")
#+end_src

#+RESULTS:
: Running on PyMC v5.0.2

* Functions

#+begin_src python :tangle yes :comments both :results none :session :exports both
def inv_logit(p):
    return 1. / (1. + np.exp(-p))
#+end_src

* Simulating data

Create output directory.

#+begin_src python :tangle yes :comments both :results output :session :exports both
out_dir = "outputs/sim-data-2lv/"
#+end_src

#+RESULTS:

#+begin_src python :tangle yes :results output :session :exports both
# Set seed for repeatability
SEED = 1234
rng = np.random.default_rng(SEED)

# Number of sites and species
n_sites = 100
n_species = 30
# Number of explanatory variables (including intercept)
n_p = 2
# Number of latent variables
n_q = 2

# Ecological variables
Int = np.array([1] * n_sites)
x = rng.normal(0, 1, size=n_sites * (n_p - 1))
X = np.concatenate((Int, x)).reshape(n_sites, n_p, order="F")
print("X.shape:")
print(X.shape)
print("\nX[:5,]:")
print(X[:5,])
# Number of explicative variables
n_p = X.shape[1]

# Latent variables
w = rng.normal(0, 1, size=n_sites * n_q)
W_target = w.reshape(n_sites, n_q)
print("\nW.target.shape:")
print(W_target.shape)
print("\nW_target[:5,]:")
print(W_target[:5,])
# (Check that W_target are independant)
R_W = np.corrcoef(W_target, rowvar=False)
print("\nR_W:")
print(R_W)

# Fixed species effects beta
beta_target = rng.uniform(-1, 1, n_p * n_species).reshape(n_species, n_p)

# Factor loading lambda
lambda_target = rng.uniform(-1, 1, n_q * n_species).reshape(n_species, n_q)
# Decreasing importance of the latent axis
axis_imp = np.arange(n_q, 0, -1)
for i in range(n_q):
    lambda_target[:, i] = lambda_target[:, i] * axis_imp[i]
# Constraints on lambda
for i in range(n_q):
    lambda_target[i, (i + 1):] = 0
# Small negative values on diagonal
lambda_target[np.arange(n_q), np.arange(n_q)] = np.array([-0.1] * n_q)
# Large positive values for following species
for i in range(n_q):
    lambda_target[n_q + i, i] = n_q - i
    lambda_target[n_q + i, (i + 1):] = 0
print("\nlambda_target.shape:")
print(lambda_target.shape)
print("\nlambda_target[:6,]:")
print(lambda_target[:6,])

# Variance of random site effects 
sigma_alpha_target = 0.5
# Random site effects
alpha_target = rng.normal(loc=0, scale=sigma_alpha_target, size=n_sites)

# Probabilities
Xbeta_target = np.matmul(X, beta_target.transpose())
Wlambda_target = np.matmul(W_target, lambda_target.transpose()) 
logit_theta_target = alpha_target[:, np.newaxis] + Xbeta_target + Wlambda_target
theta_target = inv_logit(logit_theta_target)

# Simulated occurrences
Y = rng.binomial(n=1, p=theta_target)
print("\nY.shape:")
print(Y.shape)

# Save data-set
with open(out_dir + "data.pkl", "wb") as f:
    data_dump = cloudpickle.dumps({"Y": Y, "X": X})
    f.write(data_dump)
#+end_src

#+RESULTS:
#+begin_example
X.shape:
(100, 2)

X[:5,]:
[[ 1.         -1.60383681]
 [ 1.          0.06409991]
 [ 1.          0.7408913 ]
 [ 1.          0.15261919]
 [ 1.          0.86374389]]

W.target.shape:
(100, 2)

W_target[:5,]:
[[ 2.25392546  0.1616142 ]
 [ 0.83377881 -1.58010947]
 [ 1.01058529  0.72186786]
 [-0.58363204  0.68284538]
 [ 0.50536578  1.00145778]]

R_W:
[[1.        0.0422377]
 [0.0422377 1.       ]]

lambda_target.shape:
(30, 2)

lambda_target[:6,]:
[[-0.1         0.        ]
 [-0.96376217 -0.1       ]
 [ 2.          0.        ]
 [-1.71765991  1.        ]
 [ 0.07843035 -0.83177571]
 [-0.50342304  0.46545259]]

Y.shape:
(100, 30)
#+end_example

Histogram of Wlambda.

#+begin_src python :tangle yes :comments both :results file :session :exports both
ofile = os.path.join(out_dir, "hist_Wlambda.png")
fig = plt.figure()
plt.hist(Wlambda_target.flatten(), bins=20)
fig.savefig(ofile)
ofile
#+end_src

#+ATTR_HTML: :width 600
#+RESULTS:
[[file:outputs/sim-data-2lv/hist_Wlambda.png]]

* Model

#+begin_src python :tangle yes :comments both :results output :session :exports both
HALFNORMAL_SCALE = 1. / np.sqrt(1. - 2. / np.pi)
#+end_src

#+RESULTS:

We create a function to expand a packed block triangular matrix. Triangular matrices can be stored with better space efficiency by storing the non-zero values in a one-dimensional array. This function is an adaptation of =pm.expand.packed.triangular=.

#+begin_src python :tangle yes :comments both :results output :session :exports both
def expand_packed_block_triangular(n_species, n_q, packed, diag=None, mtype="pytensor"):
    # like pm.expand_packed_triangular, but with n_species > n_q.
    assert mtype in {"pytensor", "numpy"}
    assert n_species >= n_q

    def set_(M, i_, v_):
        if mtype == "pytensor":
            return pt.set_subtensor(M[i_], v_)
        M[i_] = v_
        return M

    out = pt.zeros((n_species, n_q), dtype=float) if mtype == "pytensor" else np.zeros((n_species, n_q), dtype=float)
    if diag is None:
        idxs = np.tril_indices(n_species, m=n_q)
        out = set_(out, idxs, packed)
    else:
        idxs = np.tril_indices(n_species, k=-1, m=n_q)
        out = set_(out, idxs, packed)
        idxs = (np.arange(n_q), np.arange(n_q))
        out = set_(out, idxs, diag)
    return out
#+end_src

#+RESULTS:

We define another function which creates a diagonal matrix with positive values on the diagonal.

#+begin_src python :tangle yes :comments both :results output :session :exports both
def makeLambda(n_species, n_q, dim_names):
    # Number of non-zeros factor loadings
    n_L_packed = int(n_species * n_q - n_q * (n_q - 1) / 2 - n_q)
    # Diagonal matrix
    L_diag = pm.HalfNormal("L_diag", sigma=HALFNORMAL_SCALE*np.sqrt(10), shape=n_q)
    # Packed Lambda
    L_packed = pm.Normal("L_packed", mu=0, sigma=np.sqrt(10), shape=n_L_packed)
    L = expand_packed_block_triangular(n_species, n_q, L_packed, diag=L_diag)
    Lambda = pm.Deterministic("Lambda", L, dims=dim_names)
    return Lambda
#+end_src

#+RESULTS:

#+begin_src python :tangle yes :comments both :results output :session :exports both
with pm.Model() as model:
    # Hyperpriors
    sigma_alpha = pm.HalfNormal("sigma_alpha", sigma=1.0)
    # Priors
    # Site random effect
    alpha = pm.Normal("alpha", mu=0, sigma=sigma_alpha, shape=n_sites, dims="sites")
    # Latent variables
    W = pm.Normal("W", mu=0, sigma=1, shape=(n_sites, n_q), dims=("sites", "latent_axis"))
    # Species effects
    beta = pm.Normal("beta", mu=0, sigma=1, shape=(n_species, n_p), dims=("species", "fixed_effects"))
    # Factor loadings with constraints
    Lambda = makeLambda(n_species, n_q, ("species", "latent_axis"))
    # Likelihood
    Xbeta = pm.math.dot(X, beta.transpose())
    Wlambda = pm.math.dot(W, Lambda.transpose()) 
    logit_theta = alpha[:, np.newaxis] + Xbeta + Wlambda
    obs = pm.Bernoulli("obs", logit_p=logit_theta, observed=Y)
#+end_src

#+RESULTS:

Parameters for MCMC sampling:

#+begin_src python :tangle yes :comments both :results output :session :exports both
CORES = 2
SAMPLE_KWARGS = {
    'draws': 1000,
    'cores': CORES,
    'init': 'auto',
    'tune': 1000,
    'random_seed': [SEED + i for i in range(CORES)]
}
#+end_src

#+RESULTS:

#+begin_src python :tangle yes :comments both :results silent :session :exports code
# Inference
with model:
    trace = pm.sample(**SAMPLE_KWARGS)
#+end_src

Save model with cloudpickle (cf. [[https://github.com/pymc-devs/pymc/issues/5886][link]]).

#+begin_src python :tangle yes :comments both :results silent :session :exports both
with open(out_dir + "model_trace.pkl", "wb") as f:
     model_trace_dump = cloudpickle.dumps({'model': model, 'trace': trace})
     f.write(model_trace_dump)
#+end_src

Then, model results can be loaded with the following code:

#+begin_src python :tangle yes :comments both :eval no :exports code
f = open(out_dir + "model_trace.pkl", "rb")
model_trace = cloudpickle.loads(f.read())
#+end_src

* Convergence and model performance

** Plotting traces

#+begin_src python :tangle yes :comments both :results file :session :exports both
ofile = out_dir + "trace.png"
with model:
    axes = az.plot_trace(trace,
                         var_names=["alpha", "beta",
                                    "sigma_alpha"])
fig = axes.ravel()[0].figure
fig.savefig(ofile)
ofile
#+end_src

#+ATTR_HTML: :width 900
#+RESULTS:
[[file:outputs/sim-data-2lv/trace.png]]

** Parameter estimates.

#+begin_src python :tangle yes :comments both :results output :session :exports both
with model:
    summary = az.summary(trace,
                         var_names=["alpha", "beta",
                                    "sigma_alpha"], round_to=2)
summary.to_csv(out_dir + "model_summary.txt")
#+end_src

#+RESULTS:

#+begin_src python :tangle yes :comments both :results output :session :exports code
with model:
    alpha_est = az.summary(trace, var_names=["alpha"], round_to=2)
    beta_est = az.summary(trace, var_names=["beta"], round_to=2)
    lambda_est = az.summary(trace, var_names=["Lambda"], round_to=2)
    lambda_0_est = az.summary(trace,
                              var_names=["Lambda"],
                              coords={"latent_axis": [0]},
                              round_to=2)
    lambda_1_est = az.summary(trace,
                              var_names=["Lambda"],
                              coords={"latent_axis": [1]},
                              round_to=2)
    W_est = az.summary(trace, var_names=["W"], round_to=2)
    W_0_est = az.summary(trace, var_names=["W"],
                         coords={"latent_axis": [0]},
                         round_to=2)
    W_1_est = az.summary(trace, var_names=["W"],
                         coords={"latent_axis": [1]},
                         round_to=2)
#+end_src

#+RESULTS:
: /home/ghislain/.pyenv/versions/miniconda3-latest/envs/JSDM-PyMC/lib/python3.9/site-packages/arviz/stats/diagnostics.py:584: RuntimeWarning: invalid value encountered in scalar divide
:   (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)
: /home/ghislain/.pyenv/versions/miniconda3-latest/envs/JSDM-PyMC/lib/python3.9/site-packages/arviz/stats/diagnostics.py:584: RuntimeWarning: invalid value encountered in scalar divide
:   (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)

# This warning is due to the constraints lambda[0, 1]=0. No stats can be computed for this constant parameter.

#+RESULTS:

** Traces for constrained parameters

*** Factor loadings on the diagonal

#+begin_src python :tangle yes :comments both :results file :session :exports both
ofile = out_dir + "trace_lambda_00.png"
with model:
    axes = az.plot_trace(trace,
                         var_names=["Lambda"],
                         coords={"species": [0],
                                 "latent_axis": [0]})
fig = axes.ravel()[0].figure
fig.savefig(ofile)
ofile
#+end_src

#+ATTR_HTML: :width 750
#+RESULTS:
[[file:outputs/sim-data-2lv/trace_lambda_00.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports both
ofile = out_dir + "trace_lambda_11.png"
with model:
    axes = az.plot_trace(trace,
                         var_names=["Lambda"],
                         coords={"species": [1],
                                 "latent_axis": [1]})
fig = axes.ravel()[0].figure
fig.savefig(ofile)
ofile
#+end_src

#+ATTR_HTML: :width 750
#+RESULTS:
[[file:outputs/sim-data-2lv/trace_lambda_11.png]]

For these two lambdas, the MCMCs do not converge and samples are concentrated around the zero values, the closest positive value to the target values of -0.1.

#+begin_src python :tangle yes :comments both :results value raw :session :exports both
lambda_diag = lambda_est.loc[["Lambda[0, 0]", "Lambda[1, 1]"], ["mean", "sd", "r_hat"]]
lambda_diag["target_value"] = [lambda_target[0, 0], lambda_target[1, 1]]
tabulate(lambda_diag, headers="keys", tablefmt="orgtbl", showindex=True)
#+end_src

#+RESULTS:
|              | mean |   sd | r_hat | target_value |
|--------------+------+------+-------+--------------|
| Lambda[0, 0] | 0.76 | 0.42 |  1.05 |         -0.1 |
| Lambda[1, 1] | 1.07 | 0.47 |   1.1 |         -0.1 |

*** Species with high factor loadings

#+begin_src python :tangle yes :comments both :results file :session :exports both
ofile = out_dir + "trace_lambda_20.png"
with model:
    axes = az.plot_trace(trace,
                         var_names=["Lambda"],
                         coords={"species": [2],
                                 "latent_axis": [0]})
fig = axes.ravel()[0].figure
fig.savefig(ofile)
ofile
#+end_src

#+ATTR_HTML: :width 750
#+RESULTS:
[[file:outputs/sim-data-2lv/trace_lambda_20.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports both
ofile = out_dir + "trace_lambda_31.png"
with model:
    axes = az.plot_trace(trace,
                         var_names=["Lambda"],
                         coords={"species": [3],
                                 "latent_axis": [1]})
fig = axes.ravel()[0].figure
fig.savefig(ofile)
ofile
#+end_src

#+ATTR_HTML: :width 750
#+RESULTS:
[[file:outputs/sim-data-2lv/trace_lambda_31.png]]

For species with high factor loadings, the MCMCs do not converge (r_hat >> 1) and oscillate between positive and negative values (bimodal distributions) because the sign of the factor loadings are not correctly set by the constraints on the diagonal. The mean parameter estimates end up being close to zero while the target parameter values are far from zero (values 2 and -2).

#+begin_src python :tangle yes :comments both :results value raw :session :exports both
lambda_high = lambda_est.loc[["Lambda[2, 0]", "Lambda[3, 1]"], ["mean", "sd", "r_hat"]]
lambda_high["target_value"] = [lambda_target[2, 0], lambda_target[3, 1]]
tabulate(lambda_high, headers="keys", tablefmt="orgtbl", showindex=True)
#+end_src

#+RESULTS:
|              |  mean |   sd | r_hat | target_value |
|--------------+-------+------+-------+--------------|
| Lambda[2, 0] | -0.28 | 1.06 |  1.38 |            2 |
| Lambda[3, 1] |  1.54 | 1.21 |  1.34 |            1 |

** Convergence criteria

We compute the mean r_hat for each category of parameters.

#+begin_src python :tangle yes :comments both :results value raw :session :exports both
# Compute r_hat mean and std
rhat_alpha_mean = round(alpha_est["r_hat"].mean(), 2)
rhat_alpha_std = round(alpha_est["r_hat"].std(), 2)
rhat_beta_mean = round(beta_est["r_hat"].mean(), 2)
rhat_beta_std = round(beta_est["r_hat"].std(), 2)
rhat_W_mean = round(W_est["r_hat"].mean(), 2)
rhat_W_std = round(W_est["r_hat"].std(), 2)
rhat_lambda_mean = round(lambda_est["r_hat"].mean(), 2)
rhat_lambda_std = round(lambda_est["r_hat"].std(), 2)
rhat_lambda_diag_mean = round(lambda_est.loc[["Lambda[0, 0]", "Lambda[1, 1]"], ["r_hat"]]["r_hat"].mean(), 2)
rhat_lambda_diag_std = round(lambda_est.loc[["Lambda[0, 0]", "Lambda[1, 1]"], ["r_hat"]]["r_hat"].std(), 2)
rhat_lambda_high_mean = round(lambda_est.loc[["Lambda[2, 0]", "Lambda[3, 1]"], ["r_hat"]]["r_hat"].mean(), 2)
rhat_lambda_high_std = round(lambda_est.loc[["Lambda[2, 0]", "Lambda[3, 1]"], ["r_hat"]]["r_hat"].std(), 2)

# Build dataframe
par_names = ["alpha", "beta", "W", "lambda", "lambda_diag", "lambda_high"]
mean_val = [eval("rhat_" + x + "_mean") for x in par_names]
std_val = [eval("rhat_" + x + "_std") for x in par_names]

rhat_dic = {"par": par_names,
            "r_hat_mean": mean_val, "rhat_std": std_val}
rhat_df = pd.DataFrame(rhat_dic)
tabulate(rhat_df, headers="keys", tablefmt="orgtbl", showindex=False)
#+end_src

#+RESULTS:
| par         | r_hat_mean | rhat_std |
|-------------+------------+----------|
| alpha       |          1 |        0 |
| beta        |          1 |        0 |
| W           |       1.12 |     0.09 |
| lambda      |       1.21 |     0.12 |
| lambda_diag |       1.08 |     0.04 |
| lambda_high |       1.36 |     0.03 |

** Predicted vs. target parameter values

#+begin_src python :tangle yes :comments both :results output :session :exports both
# alpha
f = out_dir + "alpha.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(alpha_target, alpha_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.set_title("alpha")
fig.savefig(f)

# beta
f = out_dir + "beta.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(beta_target.flatten(), beta_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.set_title("beta")
fig.savefig(f)

# W_0
f = out_dir + "W_0.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(W_target[:, 0], W_0_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("W_0")
fig.savefig(f)

# W_1
f = out_dir + "W_1.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(W_target[:, 1], W_1_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("W_1")
fig.savefig(f)

# lambda_0
f = out_dir + "lambda_0.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(lambda_target[:, 0], lambda_0_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("lambda_0")
fig.savefig(f)

# lambda_1
f = out_dir + "lambda_1.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(lambda_target[:, 1], lambda_1_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("lambda_1")
fig.savefig(f)

# W_lambda
W_lambda_est = np.matmul(
    np.asarray(W_est["mean"]).reshape(n_sites, n_q),
    np.asarray(lambda_est["mean"]).reshape(n_species, n_q).transpose())
f = out_dir + "W_lambda.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(Wlambda_target.flatten(), W_lambda_est.flatten(), c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.set_title("W_lambda")
fig.savefig(f)
#+end_src

#+RESULTS:

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_0.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/W_0.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_1.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/W_1.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "lambda_0.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/lambda_0.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "lambda_1.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/lambda_1.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_lambda.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/W_lambda.png]]

#+ATTR_HTML: :width 375

* Correcting for species order
** Sorting species

Species with high factor values are used for constraints.

#+begin_src python :tangle yes :comments both :results output :session :exports both
Y_sort = np.copy(Y)
Y_sort[:, 0] = Y[:, 2]
Y_sort[:, 1] = Y[:, 3]
Y_sort[:, 2] = Y[:, 0]
Y_sort[:, 3] = Y[:, 1]
#+end_src

#+RESULTS:

** Statistical model

#+begin_src python :tangle yes :comments both :results output :session :exports both
with pm.Model() as model_sort:
    # Hyperpriors
    sigma_alpha = pm.HalfNormal("sigma_alpha", sigma=1.0)
    # Priors
    # Site random effect
    alpha = pm.Normal("alpha", mu=0, sigma=sigma_alpha, shape=n_sites, dims="sites")
    # Latent variables
    W = pm.Normal("W", mu=0, sigma=1, shape=(n_sites, n_q), dims=("sites", "latent_axis"))
    # Species effects
    beta = pm.Normal("beta", mu=0, sigma=1, shape=(n_species, n_p), dims=("species", "fixed_effects"))
    # Factor loadings with constraints
    Lambda = makeLambda(n_species, n_q, ("species", "latent_axis"))
    # Likelihood
    Xbeta = pm.math.dot(X, beta.transpose())
    Wlambda = pm.math.dot(W, Lambda.transpose()) 
    logit_theta = alpha[:, np.newaxis] + Xbeta + Wlambda
    obs = pm.Bernoulli("obs", logit_p=logit_theta, observed=Y_sort)
#+end_src

#+RESULTS:

#+begin_src python :tangle yes :comments both :results silent :session :exports code
# Inference
with model_sort:
    trace_sort = pm.sample(**SAMPLE_KWARGS)
#+end_src

Save model with cloudpickle.

#+begin_src python :tangle yes :comments both :results silent :session :exports both
with open(out_dir + "model_trace_sort.pkl", "wb") as f:
     model_trace_dump = cloudpickle.dumps({'model': model_sort, 'trace': trace_sort})
     f.write(model_trace_dump)
#+end_src

** Convergence and model performance

#+begin_src python :tangle yes :comments both :results output :session :exports code
with model_sort:
    alpha_est = az.summary(trace_sort, var_names=["alpha"], round_to=2)
    beta_est = az.summary(trace_sort, var_names=["beta"], round_to=2)
    lambda_est = az.summary(trace_sort, var_names=["Lambda"], round_to=2)
    lambda_0_est = az.summary(trace_sort,
                              var_names=["Lambda"],
                              coords={"latent_axis": [0]},
                              round_to=2)
    lambda_1_est = az.summary(trace_sort,
                              var_names=["Lambda"],
                              coords={"latent_axis": [1]},
                              round_to=2)
    W_est = az.summary(trace_sort, var_names=["W"], round_to=2)
    W_0_est = az.summary(trace_sort, var_names=["W"],
                         coords={"latent_axis": [0]},
                         round_to=2)
    W_1_est = az.summary(trace_sort, var_names=["W"],
                         coords={"latent_axis": [1]},
                         round_to=2)
#+end_src

#+RESULTS:
: /home/ghislain/.pyenv/versions/miniconda3-latest/envs/JSDM-PyMC/lib/python3.9/site-packages/arviz/stats/diagnostics.py:584: RuntimeWarning: invalid value encountered in scalar divide
:   (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)
: /home/ghislain/.pyenv/versions/miniconda3-latest/envs/JSDM-PyMC/lib/python3.9/site-packages/arviz/stats/diagnostics.py:584: RuntimeWarning: invalid value encountered in scalar divide
:   (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)

#+begin_src python :tangle yes :comments both :results value raw :session :exports both
lambda_diag = lambda_est.loc[["Lambda[0, 0]", "Lambda[1, 1]"], ["mean", "sd", "r_hat"]]
lambda_diag["target_value"] = [lambda_target[2, 0], lambda_target[3, 1]]
col_names = ["Distance", "Npixels", "Area", "Cumulation", "Percentage"]
tabulate(lambda_diag, headers="keys", tablefmt="orgtbl", showindex=True)
#+end_src

#+RESULTS:
|              | mean |   sd | r_hat | target_value |
|--------------+------+------+-------+--------------|
| Lambda[0, 0] | 1.67 | 0.49 |     1 |            2 |
| Lambda[1, 1] |  0.2 | 0.19 |  1.01 |            1 |

#+begin_src python :tangle yes :comments both :results value raw :session :exports both
# Compute r_hat mean and std
rhat_alpha_mean = round(alpha_est["r_hat"].mean(), 2)
rhat_alpha_std = round(alpha_est["r_hat"].std(), 2)
rhat_beta_mean = round(beta_est["r_hat"].mean(), 2)
rhat_beta_std = round(beta_est["r_hat"].std(), 2)
rhat_W_mean = round(W_est["r_hat"].mean(), 2)
rhat_W_std = round(W_est["r_hat"].std(), 2)
rhat_lambda_mean = round(lambda_est["r_hat"].mean(), 2)
rhat_lambda_std = round(lambda_est["r_hat"].std(), 2)
rhat_lambda_diag_mean = round(lambda_est.loc[["Lambda[0, 0]", "Lambda[1, 1]"], ["r_hat"]]["r_hat"].mean(), 2)
rhat_lambda_diag_std = round(lambda_est.loc[["Lambda[0, 0]", "Lambda[1, 1]"], ["r_hat"]]["r_hat"].std(), 2)
rhat_lambda_small_mean = round(lambda_est.loc[["Lambda[2, 0]", "Lambda[3, 1]"], ["r_hat"]]["r_hat"].mean(), 2)
rhat_lambda_small_std = round(lambda_est.loc[["Lambda[2, 0]", "Lambda[3, 1]"], ["r_hat"]]["r_hat"].std(), 2)

# Build dataframe
par_names = ["alpha", "beta", "W", "lambda", "lambda_diag", "lambda_small"]
mean_val = [eval("rhat_" + x + "_mean") for x in par_names]
std_val = [eval("rhat_" + x + "_std") for x in par_names]

rhat_dic = {"par": par_names,
            "r_hat_mean": mean_val, "rhat_std": std_val}
rhat_df = pd.DataFrame(rhat_dic)
tabulate(rhat_df, headers="keys", tablefmt="orgtbl", showindex=False)
#+end_src

#+RESULTS:
| par          | r_hat_mean | rhat_std |
|--------------+------------+----------|
| alpha        |          1 |        0 |
| beta         |          1 |        0 |
| W            |          1 |        0 |
| lambda       |          1 |        0 |
| lambda_diag  |          1 |     0.01 |
| lambda_small |          1 |        0 |

** Predicted vs. target parameter values

#+begin_src python :tangle yes :comments both :results output :session :exports both
# Sorted index
id = [2, 3, 0, 1] + list(np.arange(4, n_species))

# alpha
f = out_dir + "alpha_sort.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(alpha_target, alpha_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.set_title("alpha_sort")
fig.savefig(f)

# beta
f = out_dir + "beta_sort.png"
fig, ax = plt.subplots(figsize=(6, 6))
beta_hat = np.asarray(beta_est["mean"]).reshape(n_species, n_p)[id, :]
ax.scatter(beta_target.flatten(), beta_hat.flatten(), c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.set_title("beta_sort")
fig.savefig(f)

# W_0
f = out_dir + "W_0_sort.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(W_target[:, 0], W_0_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("W_0_sort")
fig.savefig(f)

# W_1
f = out_dir + "W_1_sort.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(W_target[:, 1], W_1_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("W_1_sort")
fig.savefig(f)

# lambda_0
f = out_dir + "lambda_0_sort.png"
fig, ax = plt.subplots(figsize=(6, 6))
lambda_0_hat = lambda_0_est["mean"][id]
ax.scatter(lambda_target[:, 0], lambda_0_hat, c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("lambda_0_sort")
fig.savefig(f)

# lambda_1
f = out_dir + "lambda_1_sort.png"
fig, ax = plt.subplots(figsize=(6, 6))
lambda_1_hat = lambda_1_est["mean"][id]
ax.scatter(lambda_target[:, 1], lambda_1_hat, c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("lambda_1_sort")
fig.savefig(f)

# W_lambda
lambda_hat = np.asarray(lambda_est["mean"]).reshape(n_species, n_q)[id, :]
W_lambda_est = np.matmul(
    np.asarray(W_est["mean"]).reshape(n_sites, n_q),
    lambda_hat.transpose())
f = out_dir + "W_lambda_sort.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(Wlambda_target.flatten(), W_lambda_est.flatten(), c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.set_title("W_lambda_sort")
fig.savefig(f)
#+end_src

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_0.png")
#+end_src

#+ATTR_HTML: :width 375 :style float:left;
#+RESULTS:
[[file:outputs/sim-data-2lv/W_0.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_0_sort.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/W_0_sort.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_1.png")
#+end_src

#+ATTR_HTML: :width 375 :style float:left;
#+RESULTS:
[[file:outputs/sim-data-2lv/W_1.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_1_sort.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/W_1_sort.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "lambda_0.png")
#+end_src

#+ATTR_HTML: :width 375 :style float:left;
#+RESULTS:
[[file:outputs/sim-data-2lv/lambda_0.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "lambda_0_sort.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/lambda_0_sort.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "lambda_1.png")
#+end_src

#+ATTR_HTML: :width 375 :style float:left;
#+RESULTS:
[[file:outputs/sim-data-2lv/lambda_1.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "lambda_1_sort.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/lambda_1_sort.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_lambda.png")
#+end_src

#+ATTR_HTML: :width 375 :style float:left;
#+RESULTS:
[[file:outputs/sim-data-2lv/W_lambda.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_lambda_sort.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/W_lambda_sort.png]]

* Automatic sorting of species with PCAÂ on residuals
** Unsorted data

#+begin_src python :tangle yes :comments both :results output :session :exports both
f = open(out_dir + "data.pkl", "rb")
data = cloudpickle.loads(f.read())
Y = data["Y"]
X = data["X"]
print("X.shape:")
print(X.shape)
print("\nX[:5,]:")
print(X[:5,])
print("\nY.shape:")
print(Y.shape)
#+end_src

#+RESULTS:
#+begin_example
X.shape:
(100, 2)

X[:5,]:
[[ 1.         -1.60383681]
 [ 1.          0.06409991]
 [ 1.          0.7408913 ]
 [ 1.          0.15261919]
 [ 1.          0.86374389]]

Y.shape:
(100, 30)
#+end_example

** Statistical model with residuals

#+begin_src python :tangle yes :comments both :results output :session :exports both
with pm.Model() as model_res:
    # Hyperpriors
    sigma_alpha = pm.HalfNormal("sigma_alpha", sigma=1.0)
    # Priors
    # Site random effect
    alpha = pm.Normal("alpha", mu=0, sigma=sigma_alpha, shape=n_sites)
    # Species effects
    beta = pm.Normal("beta", mu=0, sigma=1, shape=(n_species, n_p))
    # Likelihood
    Xbeta = pm.math.dot(X, beta.transpose())
    m = pm.Deterministic("mu", alpha[:, np.newaxis] + Xbeta)
    logit_theta = pm.Normal("logit_theta", mu=m, sigma=1)
    e = pm.Deterministic("error", logit_theta - m)
    obs = pm.Bernoulli("obs", logit_p=logit_theta, observed=Y)
#+end_src

#+RESULTS:

#+begin_src python :tangle yes :comments both :results silent :session :exports code
# Inference
with model_res:
    trace_res = pm.sample(**SAMPLE_KWARGS)
#+end_src

Save model with cloudpickle.

#+begin_src python :tangle yes :comments both :results silent :session :exports both
with open(out_dir + "model_trace_res.pkl", "wb") as f:
    model_trace_dump = cloudpickle.dumps({'model': model_res, 'trace': trace_res})
    f.write(model_trace_dump)
#+end_src

Get residuals.

#+begin_src python :tangle yes :comments both :results output :session :exports both
with model_res:
    error_est = az.summary(trace_res, var_names=["error"], round_to=2)
e = np.asarray(error_est["mean"]).reshape(n_sites, n_species)
#+end_src

#+RESULTS:

#+begin_src python :tangle yes :comments both :results file :session :exports both
ofile = os.path.join(out_dir, "hist_residuals.png")
fig = plt.figure()
plt.hist(e.flatten(), bins=20)
fig.savefig(ofile)
ofile
#+end_src

#+ATTR_HTML: :width 600
#+RESULTS:
[[file:outputs/sim-data-2lv/hist_residuals.png]]

Correlation between residuals and Wlambda.

#+begin_src python :tangle yes :comments both :results file :session :exports both
ofile = out_dir + "corr_res_Wlambda.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(Wlambda_target, e, c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.set_xlabel("Wlambda_target")
ax.set_ylabel("Estimated residuals")
ax.set_title("corr_res_Wlambda")
fig.savefig(ofile)
ofile
#+end_src

#+ATTR_HTML: :width 600
#+RESULTS:
[[file:outputs/sim-data-2lv/corr_res_Wlambda.png]]

** PCA on residuals

Make the PCA on residuals to find the coordinates of the species on two axis.

#+begin_src python :tangle yes :comments both :results output :session :exports both
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

pca = PCA(n_components=2)
e_cr = StandardScaler().fit_transform(e)
pca_features = pca.fit_transform(e_cr)
pca_features.shape
print(pca.explained_variance_ratio_)
#+end_src

#+RESULTS:
: [0.21591098 0.08906021]

The first axis explains a higher percentage of the inertia than the second axis.

#+begin_src python :tangle yes :comments both :results output :session :exports both
pca_comp = pca.components_.transpose()
print(pca_comp)
#+end_src

#+RESULTS:
#+begin_example
[[ 0.04692378 -0.21384329]
 [ 0.18100145  0.03470675]
 [-0.22266366 -0.118447  ]
 [ 0.24103108 -0.21171194]
 [ 0.01140621  0.34386345]
 [ 0.04424672 -0.1326954 ]
 [ 0.24147544 -0.10418143]
 [-0.22460682  0.05477689]
 [-0.1001427  -0.20516141]
 [-0.18297192  0.14689355]
 [-0.13958024 -0.26841004]
 [-0.15698748  0.24706136]
 [-0.24997254 -0.30120634]
 [-0.14926731  0.27085541]
 [ 0.15531343  0.00151203]
 [ 0.18676268  0.06231319]
 [-0.26034287 -0.09968252]
 [ 0.20706059 -0.16658225]
 [-0.0437241  -0.20905267]
 [-0.12967744 -0.21507216]
 [ 0.07620406 -0.3192065 ]
 [-0.13761504  0.25479687]
 [ 0.23606282  0.01313387]
 [-0.20617314  0.01725708]
 [ 0.29775449  0.11980329]
 [ 0.13900535 -0.01052118]
 [ 0.19418434  0.09522476]
 [-0.19307443  0.15404952]
 [ 0.12722835 -0.06802791]
 [ 0.25218927  0.18156252]]
#+end_example

Identify the species which influences most each component.

#+begin_src python :tangle yes :comments both :results output :session :exports both
pca_comp_abs = np.abs(pca_comp)
sp_sel = np.argmax(pca_comp_abs, axis=0)
print(sp_sel)
#+end_src

#+RESULTS:
: [24  4]

We correctly identified the two species. We look again at the factor loadings for these two species.

#+begin_src python :tangle yes :comments both :results output :session :exports both
print(lambda_target[sp_sel, :])
#+end_src

#+RESULTS:
: [[-1.92085221 -0.39393461]
:  [ 0.07843035 -0.83177571]]

Sorting species.

#+begin_src python :tangle yes :comments both :results output :session :exports both
Y_auto = np.copy(Y)
Y_auto[:, 0] = Y[:, sp_sel[0]]
Y_auto[:, 1] = Y[:, sp_sel[1]]
Y_auto[:, sp_sel[0]] = Y[:, 0]
Y_auto[:, sp_sel[1]] = Y[:, 1]
#+end_src

#+RESULTS:

** Correlation between loadings and species coordinates on the PCA axis

#+begin_src python :tangle yes :comments both :results output :session :exports both
cor = np.corrcoef(np.abs(lambda_target.flatten()), np.abs(pca_comp.flatten()))
print(cor)
#+end_src

#+RESULTS:
: [[1.         0.63155205]
:  [0.63155205 1.        ]]

#+begin_src python :tangle yes :comments both :results file :session :exports both
ofile = os.path.join(out_dir, "cor_lambda_coordPCA_e.png")
fig, axs = plt.subplots(2, sharex=True)
axs[0].scatter(np.abs(lambda_target[:, 0]), np.abs(pca_comp[:, 0]), c="b")
axs[1].scatter(np.abs(lambda_target[:, 1]), np.abs(pca_comp[:, 1]), c="g")
for ax in axs.flat:
    ax.set(xlabel="lambda targets (abs)", ylabel="Coord. on PCA axis (abs)")
fig.savefig(ofile)
ofile
#+end_src

#+ATTR_HTML: :width 600
#+RESULTS:
[[file:outputs/sim-data-2lv/cor_lambda_coordPCA_e.png]]
 
** Statistical model with sorted species

#+begin_src python :tangle yes :comments both :results output :session :exports both
with pm.Model() as model_auto:
    # Hyperpriors
    sigma_alpha = pm.HalfNormal("sigma_alpha", sigma=1.0)
    # Priors
    # Site random effect
    alpha = pm.Normal("alpha", mu=0, sigma=sigma_alpha, shape=n_sites, dims="sites")
    # Latent variables
    W = pm.Normal("W", mu=0, sigma=1, shape=(n_sites, n_q), dims=("sites", "latent_axis"))
    # Species effects
    beta = pm.Normal("beta", mu=0, sigma=1, shape=(n_species, n_p), dims=("species", "fixed_effects"))
    # Factor loadings with constraints
    Lambda = makeLambda(n_species, n_q, ("species", "latent_axis"))
    # Likelihood
    Xbeta = pm.math.dot(X, beta.transpose())
    Wlambda = pm.math.dot(W, Lambda.transpose()) 
    logit_theta = alpha[:, np.newaxis] + Xbeta + Wlambda
    obs = pm.Bernoulli("obs", logit_p=logit_theta, observed=Y_auto)
#+end_src

#+RESULTS:

#+begin_src python :tangle yes :comments both :results silent :session :exports code
# Inference
with model_auto:
    trace_auto = pm.sample(**SAMPLE_KWARGS)
#+end_src

Save model with cloudpickle.

#+begin_src python :tangle yes :comments both :results silent :session :exports both
with open(out_dir + "model_trace_auto.pkl", "wb") as f:
    model_trace_dump = cloudpickle.dumps({'model': model_auto, 'trace': trace_auto})
    f.write(model_trace_dump)
#+end_src

** Convergence and model performance

#+begin_src python :tangle yes :comments both :results output :session :exports code
with model_auto:
    alpha_est = az.summary(trace_auto, var_names=["alpha"], round_to=2)
    beta_est = az.summary(trace_auto, var_names=["beta"], round_to=2)
    lambda_est = az.summary(trace_auto, var_names=["Lambda"], round_to=2)
    lambda_0_est = az.summary(trace_auto,
                              var_names=["Lambda"],
                              coords={"latent_axis": [0]},
                              round_to=2)
    lambda_1_est = az.summary(trace_auto,
                              var_names=["Lambda"],
                              coords={"latent_axis": [1]},
                              round_to=2)
    W_est = az.summary(trace_auto, var_names=["W"], round_to=2)
    W_0_est = az.summary(trace_auto, var_names=["W"],
                         coords={"latent_axis": [0]},
                         round_to=2)
    W_1_est = az.summary(trace_auto, var_names=["W"],
                         coords={"latent_axis": [1]},
                         round_to=2)
#+end_src

#+RESULTS:
: /home/ghislain/.pyenv/versions/miniconda3-latest/envs/JSDM-PyMC/lib/python3.9/site-packages/arviz/stats/diagnostics.py:584: RuntimeWarning: invalid value encountered in scalar divide
:   (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)
: /home/ghislain/.pyenv/versions/miniconda3-latest/envs/JSDM-PyMC/lib/python3.9/site-packages/arviz/stats/diagnostics.py:584: RuntimeWarning: invalid value encountered in scalar divide
:   (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)

#+begin_src python :tangle yes :comments both :results value raw :session :exports both
# Compute r_hat mean and std
rhat_alpha_mean = round(alpha_est["r_hat"].mean(), 2)
rhat_alpha_std = round(alpha_est["r_hat"].std(), 2)
rhat_beta_mean = round(beta_est["r_hat"].mean(), 2)
rhat_beta_std = round(beta_est["r_hat"].std(), 2)
rhat_W_mean = round(W_est["r_hat"].mean(), 2)
rhat_W_std = round(W_est["r_hat"].std(), 2)
rhat_lambda_mean = round(lambda_est["r_hat"].mean(), 2)
rhat_lambda_std = round(lambda_est["r_hat"].std(), 2)
rhat_lambda_diag_mean = round(lambda_est.loc[["Lambda[0, 0]", "Lambda[1, 1]"], ["r_hat"]]["r_hat"].mean(), 2)
rhat_lambda_diag_std = round(lambda_est.loc[["Lambda[0, 0]", "Lambda[1, 1]"], ["r_hat"]]["r_hat"].std(), 2)
rhat_lambda_small_mean = round(lambda_est.loc[["Lambda[2, 0]", "Lambda[3, 1]"], ["r_hat"]]["r_hat"].mean(), 2)
rhat_lambda_small_std = round(lambda_est.loc[["Lambda[2, 0]", "Lambda[3, 1]"], ["r_hat"]]["r_hat"].std(), 2)

# Build dataframe
par_names = ["alpha", "beta", "W", "lambda", "lambda_diag", "lambda_small"]
mean_val = [eval("rhat_" + x + "_mean") for x in par_names]
std_val = [eval("rhat_" + x + "_std") for x in par_names]
rhat_dic = {"par": par_names,
            "r_hat_mean": mean_val, "rhat_std": std_val}
rhat_df = pd.DataFrame(rhat_dic)
tabulate(rhat_df, headers="keys", tablefmt="orgtbl", showindex=False)
#+end_src

#+RESULTS:
| par          | r_hat_mean | rhat_std |
|--------------+------------+----------|
| alpha        |          1 |        0 |
| beta         |          1 |        0 |
| W            |          1 |        0 |
| lambda       |          1 |        0 |
| lambda_diag  |          1 |     0.01 |
| lambda_small |          1 |        0 |

** Predicted vs. target parameter values

Caution, the latent axis $W_i$ are inverted here.

#+begin_src python :tangle yes :comments both :results output :session :exports both
# Sorted index
id = np.arange(n_species)
id_sort = np.copy(id)
id_sort[0] = sp_sel[0]
id_sort[1] = sp_sel[1]
id_sort[sp_sel[0]] = 0
id_sort[sp_sel[1]] = 1
id = id_sort

# alpha
f = out_dir + "alpha_auto.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(alpha_target, alpha_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.set_title("alpha_auto")
fig.savefig(f)

# beta
f = out_dir + "beta_auto.png"
fig, ax = plt.subplots(figsize=(6, 6))
beta_hat = np.asarray(beta_est["mean"]).reshape(n_species, n_p)[id, :]
ax.scatter(beta_target.flatten(), beta_hat.flatten(), c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.set_title("beta_auto")
fig.savefig(f)

# W_0
f = out_dir + "W_0_auto.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(W_target[:, 0], W_0_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("W_0_auto")
fig.savefig(f)

# W_1
f = out_dir + "W_1_auto.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(W_target[:, 1], W_1_est["mean"], c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("W_1_auto")
fig.savefig(f)

# lambda_0
f = out_dir + "lambda_0_auto.png"
fig, ax = plt.subplots(figsize=(6, 6))
lambda_0_hat = lambda_0_est["mean"][id]
ax.scatter(lambda_target[:, 0], lambda_0_hat, c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("lambda_0_auto")
fig.savefig(f)

# lambda_1
f = out_dir + "lambda_1_auto.png"
fig, ax = plt.subplots(figsize=(6, 6))
lambda_1_hat = lambda_1_est["mean"][id]
ax.scatter(lambda_target[:, 1], lambda_1_hat, c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.axline((-1, 1), slope=-1, ls="--", c=".3")
ax.set_title("lambda_1_auto")
fig.savefig(f)

# W_lambda
lambda_hat = np.asarray(lambda_est["mean"]).reshape(n_species, n_q)[id, :]
W_lambda_est = np.matmul(
    np.asarray(W_est["mean"]).reshape(n_sites, n_q),
    lambda_hat.transpose())
f = out_dir + "W_lambda_auto.png"
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(Wlambda_target.flatten(), W_lambda_est.flatten(), c=".3")
ax.axline((1, 1), slope=1, ls="--", c=".3")
ax.set_title("W_lambda_auto")
fig.savefig(f)
#+end_src

#+RESULTS:

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_0.png")
#+end_src

#+ATTR_HTML: :width 375 :style float:left;
#+RESULTS:
[[file:outputs/sim-data-2lv/W_0.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_0_auto.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/W_0_auto.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_1.png")
#+end_src

#+ATTR_HTML: :width 375 :style float:left;
#+RESULTS:
[[file:outputs/sim-data-2lv/W_1.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_1_auto.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/W_1_auto.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "lambda_0.png")
#+end_src

#+ATTR_HTML: :width 375 :style float:left;
#+RESULTS:
[[file:outputs/sim-data-2lv/lambda_0.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "lambda_0_auto.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/lambda_0_auto.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "lambda_1.png")
#+end_src

#+ATTR_HTML: :width 375 :style float:left;
#+RESULTS:
[[file:outputs/sim-data-2lv/lambda_1.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "lambda_1_auto.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/lambda_1_auto.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_lambda.png")
#+end_src

#+ATTR_HTML: :width 375 :style float:left;
#+RESULTS:
[[file:outputs/sim-data-2lv/W_lambda.png]]

#+begin_src python :tangle yes :comments both :results file :session :exports results
os.path.join(out_dir, "W_lambda_auto.png")
#+end_src

#+ATTR_HTML: :width 375
#+RESULTS:
[[file:outputs/sim-data-2lv/W_lambda_auto.png]]

* Environment setup and test :noexport:

#+BEGIN_SRC python :tangle yes :comments both :results output
import sys
print(sys.executable)
#+END_SRC

#+RESULTS:
: /home/ghislain/.pyenv/versions/miniconda3-latest/envs/JSDM-PyMC/bin/python

# EOF
